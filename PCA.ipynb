{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 64), (1797,))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "digit=datasets.load_digits()\n",
    "p=digit.data\n",
    "q=digit.target\n",
    "p.shape,q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.335016</td>\n",
       "      <td>-0.043081</td>\n",
       "      <td>0.274072</td>\n",
       "      <td>-0.664478</td>\n",
       "      <td>-0.844129</td>\n",
       "      <td>-0.409724</td>\n",
       "      <td>-0.125023</td>\n",
       "      <td>-0.059078</td>\n",
       "      <td>-0.624009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.757436</td>\n",
       "      <td>-0.209785</td>\n",
       "      <td>-0.023596</td>\n",
       "      <td>-0.299081</td>\n",
       "      <td>0.086719</td>\n",
       "      <td>0.208293</td>\n",
       "      <td>-0.366771</td>\n",
       "      <td>-1.146647</td>\n",
       "      <td>-0.505670</td>\n",
       "      <td>-0.196008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.335016</td>\n",
       "      <td>-1.094937</td>\n",
       "      <td>0.038648</td>\n",
       "      <td>0.268751</td>\n",
       "      <td>-0.138020</td>\n",
       "      <td>-0.409724</td>\n",
       "      <td>-0.125023</td>\n",
       "      <td>-0.059078</td>\n",
       "      <td>-0.624009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.757436</td>\n",
       "      <td>-0.209785</td>\n",
       "      <td>-0.023596</td>\n",
       "      <td>-0.299081</td>\n",
       "      <td>-1.089383</td>\n",
       "      <td>-0.249010</td>\n",
       "      <td>0.849632</td>\n",
       "      <td>0.548561</td>\n",
       "      <td>-0.505670</td>\n",
       "      <td>-0.196008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.335016</td>\n",
       "      <td>-1.094937</td>\n",
       "      <td>-1.844742</td>\n",
       "      <td>0.735366</td>\n",
       "      <td>1.097673</td>\n",
       "      <td>-0.409724</td>\n",
       "      <td>-0.125023</td>\n",
       "      <td>-0.059078</td>\n",
       "      <td>-0.624009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259230</td>\n",
       "      <td>-0.209785</td>\n",
       "      <td>-0.023596</td>\n",
       "      <td>-0.299081</td>\n",
       "      <td>-1.089383</td>\n",
       "      <td>-2.078218</td>\n",
       "      <td>-0.164037</td>\n",
       "      <td>1.565686</td>\n",
       "      <td>1.695137</td>\n",
       "      <td>-0.196008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.335016</td>\n",
       "      <td>0.377661</td>\n",
       "      <td>0.744919</td>\n",
       "      <td>0.268751</td>\n",
       "      <td>-0.844129</td>\n",
       "      <td>-0.409724</td>\n",
       "      <td>-0.125023</td>\n",
       "      <td>-0.059078</td>\n",
       "      <td>1.879691</td>\n",
       "      <td>...</td>\n",
       "      <td>1.072563</td>\n",
       "      <td>-0.209785</td>\n",
       "      <td>-0.023596</td>\n",
       "      <td>-0.299081</td>\n",
       "      <td>0.282736</td>\n",
       "      <td>0.208293</td>\n",
       "      <td>0.241430</td>\n",
       "      <td>0.379040</td>\n",
       "      <td>-0.505670</td>\n",
       "      <td>-0.196008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.335016</td>\n",
       "      <td>-1.094937</td>\n",
       "      <td>-2.551014</td>\n",
       "      <td>-0.197863</td>\n",
       "      <td>-1.020657</td>\n",
       "      <td>-0.409724</td>\n",
       "      <td>-0.125023</td>\n",
       "      <td>-0.059078</td>\n",
       "      <td>-0.624009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.757436</td>\n",
       "      <td>-0.209785</td>\n",
       "      <td>-0.023596</td>\n",
       "      <td>-0.299081</td>\n",
       "      <td>-1.089383</td>\n",
       "      <td>-2.306869</td>\n",
       "      <td>0.849632</td>\n",
       "      <td>-0.468564</td>\n",
       "      <td>-0.505670</td>\n",
       "      <td>-0.196008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7   \\\n",
       "0  0.0 -0.335016 -0.043081  0.274072 -0.664478 -0.844129 -0.409724 -0.125023   \n",
       "1  0.0 -0.335016 -1.094937  0.038648  0.268751 -0.138020 -0.409724 -0.125023   \n",
       "2  0.0 -0.335016 -1.094937 -1.844742  0.735366  1.097673 -0.409724 -0.125023   \n",
       "3  0.0 -0.335016  0.377661  0.744919  0.268751 -0.844129 -0.409724 -0.125023   \n",
       "4  0.0 -0.335016 -1.094937 -2.551014 -0.197863 -1.020657 -0.409724 -0.125023   \n",
       "\n",
       "         8         9     ...           54        55        56        57  \\\n",
       "0 -0.059078 -0.624009    ...    -0.757436 -0.209785 -0.023596 -0.299081   \n",
       "1 -0.059078 -0.624009    ...    -0.757436 -0.209785 -0.023596 -0.299081   \n",
       "2 -0.059078 -0.624009    ...     0.259230 -0.209785 -0.023596 -0.299081   \n",
       "3 -0.059078  1.879691    ...     1.072563 -0.209785 -0.023596 -0.299081   \n",
       "4 -0.059078 -0.624009    ...    -0.757436 -0.209785 -0.023596 -0.299081   \n",
       "\n",
       "         58        59        60        61        62        63  \n",
       "0  0.086719  0.208293 -0.366771 -1.146647 -0.505670 -0.196008  \n",
       "1 -1.089383 -0.249010  0.849632  0.548561 -0.505670 -0.196008  \n",
       "2 -1.089383 -2.078218 -0.164037  1.565686  1.695137 -0.196008  \n",
       "3  0.282736  0.208293  0.241430  0.379040 -0.505670 -0.196008  \n",
       "4 -1.089383 -2.306869  0.849632 -0.468564 -0.505670 -0.196008  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=preprocessing.scale(p)\n",
    "df=pd.DataFrame(p)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train,p_test,q_train,q_test = train_test_split(p,q,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.91422304, -0.95449914, -3.94606559, ..., -0.19430345,\n",
       "         0.83108213, -0.09919926],\n",
       "       [ 0.58904438,  0.92453054,  3.92455692, ..., -0.39649298,\n",
       "        -0.76593039,  0.26152943],\n",
       "       [ 1.30203299, -0.3171763 ,  3.02338702, ..., -0.98278747,\n",
       "        -1.17313651, -0.42671305],\n",
       "       ...,\n",
       "       [ 1.02251981, -0.14778743,  2.47017527, ...,  0.25628273,\n",
       "         0.35745526, -1.22833043],\n",
       "       [ 1.07607294, -0.38095088, -2.45552182, ..., -0.7812426 ,\n",
       "         0.02264604, -0.15294581],\n",
       "       [-1.25771281, -2.22764899,  0.28391398, ...,  0.7430877 ,\n",
       "         1.81590881, -0.21773961]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=16)\n",
    "principalComponents = pca.fit_transform(p)\n",
    "principalComponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 16), (1797,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=principalComponents\n",
    "p.shape,q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LogisticRegression()\n",
    "reg.fit(p_train,q_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reg.predict(p_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.66666666666667"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(q_test,pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 51  0  0  0  0  1  0  0  1]\n",
      " [ 0  0 63  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 49  0  0  0  0  0  0]\n",
      " [ 0  1  0  0 51  0  0  0  1  1]\n",
      " [ 0  0  0  0  0 50  0  0  0  0]\n",
      " [ 1  1  0  0  0  0 57  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 56  0  1]\n",
      " [ 0  3  2  1  0  0  1  0 51  0]\n",
      " [ 0  1  0  0  0  1  0  0  0 44]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(q_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99        50\n",
      "          1       0.89      0.96      0.93        53\n",
      "          2       0.95      1.00      0.98        63\n",
      "          3       0.98      0.98      0.98        50\n",
      "          4       1.00      0.94      0.97        54\n",
      "          5       0.98      1.00      0.99        50\n",
      "          6       0.97      0.97      0.97        59\n",
      "          7       1.00      0.98      0.99        57\n",
      "          8       0.98      0.88      0.93        58\n",
      "          9       0.94      0.96      0.95        46\n",
      "\n",
      "avg / total       0.97      0.97      0.97       540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(q_test,pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
